{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zapata-git/Evaluacion-de-seguros-de-vida-para-Prudential-/blob/main/02_Modelo_Basado_en_Regresi%C3%B3n_Log%C3%ADstica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozL5OfH7B_kQ"
      },
      "source": [
        "# **ProyectoIA_Seguros_Prudential**\n",
        "*Este conjunto de datos contiene información sobre solicitantes de seguros para la compañía Prudential. Se busca crear un algoritmo que perfile solicitantes en una escala de 8 niveles.*\n",
        "\n",
        "*El conjunto de datos proporcionado contiene variables que describen los atributos de los solicitantes de seguros de vida. La tarea consiste en predecir la variable \"Response\" para cada ID en el conjunto de prueba. \"Response\" es una medida ordinal de riesgo que tiene 8 niveles.*\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hK60r-eAqAzT"
      },
      "source": [
        "#Preparación de datos.\n",
        "Importamos las bibliotecas necesarias y cargamos el conjunto de datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cEOP_ZC5Be7G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59b6a33e-f2e8-4a4b-89dd-b7db88c393c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIZG7JYArU9n"
      },
      "source": [
        "#Instalación de Jovian y Kaggle mediante pip\n",
        "\n",
        "* El paquete jovian se utiliza para guardar y compartir proyectos de ciencia de datos en línea.\n",
        "\n",
        "* El paquete kaggle proporciona una API de línea de comandos para interactuar con Kaggle, una plataforma en línea para competiciones de ciencia de datos y conjuntos de datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "K3CyPMrYZ0iu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9e5a418-19f7-4e6a-f0c9-5ba2c9c8df84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/68.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.6/68.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for uuid (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install jovian --upgrade --quiet\n",
        "!pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3cbQUIIhZ3JY"
      },
      "outputs": [],
      "source": [
        "import jovian"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "fikfzepNOge6",
        "outputId": "977e1f1c-9530-4c52-d84a-72e3c79a4f6b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-786b56ef-51fe-48bf-bf55-275cfb90fcdd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-786b56ef-51fe-48bf-bf55-275cfb90fcdd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"carlosozapata\",\"key\":\"1ea90523afd866a234b17caeb4677869\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#PARA EJECUTAR ESTA LÍNEA, EN EL COMPUTADOR QUE SE EJECUTE DEBE HABER UNA COPIA DEL JSON WEB TOKEN\n",
        "#DESCARGABLE DESDE LA PÁGINA DE UNA CUENTA DE KAGGLE EN https://www.kaggle.com/settings/account?...\n",
        "#ESTE JSON WEB TOKEN ES PERSONAL DE CADA CUENTA Y SIRVE COMO IDENTIFICADOR DE ACCESO.\n",
        "#CARGUE EL JSON QUE USTED DESCARGÓ DE SU CUENTA DE KAGGLE\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Qzu1NWq1UvL"
      },
      "source": [
        "#Extracción de los archivos del conjunto de datos descargados desde Kaggle\n",
        "\n",
        "* El conjunto de datos descargado ya contiene separados los datos de train y de test.\n",
        "\n",
        "* Los archivos quedan almacenados en el entorno de ejecución de Google Colab siempre y cuando se haya autorizado el acceso de la cuenta de Google a este. Esto se debió realizar en bloques de código anteriores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cdH7WN1OrFZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e44dbac1-8be5-455a-c962-8d9a4c0d4eca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/root/.kaggle': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!rm -r ~/.kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!mv ./kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "#!kaggle datasets list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfNtIlJSnbn6",
        "outputId": "83f771ac-cbfd-41e7-d355-03237b49b52d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading prudential-life-insurance-assessment.zip to /content\n",
            "\r  0% 0.00/3.24M [00:00<?, ?B/s]\n",
            "\r100% 3.24M/3.24M [00:00<00:00, 144MB/s]\n"
          ]
        }
      ],
      "source": [
        "#Para descargar el conjunto de datos desde Kaggle al drive local de Google\n",
        "!kaggle competitions download 'prudential-life-insurance-assessment'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2v4QzbEpWo_",
        "outputId": "0456d1be-3f41-4a31-edfa-cced25dc829f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracción de archivos en proceso...\n",
            "Extracción terminada\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "#Para descomprimir los archivos .zip que haya y guardarlos en el entorno de ejecución\n",
        "import os\n",
        "from zipfile import ZipFile \n",
        "  \n",
        "#Se indica el nombre del archivo  traído desde Kaggle\n",
        "file = \"prudential-life-insurance-assessment.zip\"\n",
        "  \n",
        "#Se abre el archivo en modo lectura\n",
        "with ZipFile(file, 'r') as zip:\n",
        "  \n",
        "    #Se extraen todos los archivos\n",
        "    print('Extracción de archivos en proceso...') \n",
        "    zip.extractall() \n",
        "    print('Extracción terminada')\n",
        "\n",
        "%cd \"/content/\"\n",
        "\n",
        "for archivo in os.listdir():\n",
        "  if archivo.endswith(\".zip\"):\n",
        "    with ZipFile(archivo, 'r') as zip_ref:\n",
        "      zip_ref.extractall(\"/content/\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "peuSiVHSCdPN"
      },
      "outputs": [],
      "source": [
        "#Se declara el conjunto de datos\n",
        "datos = pd.read_csv(\"/content/train.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXPJ_hSEJR7_"
      },
      "source": [
        "#Preprocesado.\n",
        "\n",
        "Se llenan los valores faltantes con la moda si se trata de variables categóricas y la mediana si se trata de variables numéricas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0ZPEUjbJDWm"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Cargar los archivos de datos\n",
        "#train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')\n",
        "\n",
        "# Realizar el preprocesamiento de los datos\n",
        "# Eliminar la columna \"Response\" del conjunto de entrenamiento\n",
        "X_train = datos.drop(columns = ['Id', 'Response'])\n",
        "y_train = datos['Response']\n",
        "X_test = test_data.drop(columns = ['Id'])\n",
        "\n",
        "# Imputar los valores faltantes en los datos numéricos con la mediana\n",
        "num_cols = X_train.select_dtypes(include='number').columns\n",
        "num_imputer = SimpleImputer(strategy='median')\n",
        "X_train[num_cols] = num_imputer.fit_transform(X_train[num_cols])\n",
        "X_test[num_cols] = num_imputer.transform(X_test[num_cols])\n",
        "\n",
        "# Imputar los valores faltantes en los datos categóricos con la moda\n",
        "cat_cols = X_train.select_dtypes(include='object').columns\n",
        "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
        "X_train[cat_cols] = cat_imputer.fit_transform(X_train[cat_cols])\n",
        "X_test[cat_cols] = cat_imputer.transform(X_test[cat_cols])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Aplicación de modelo de regresión logística\n",
        "Se aplica un modelo de regresión logística para observar qué sucede."
      ],
      "metadata": {
        "id": "yi1anFUBO9vZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIz8A6_mKfOd",
        "outputId": "01cfaf62-92ab-405b-a369-144c4f59a3f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión en el conjunto de validación: 0.32878673065588954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "# Codificar los datos categóricos con OneHotEncoder\n",
        "ct = ColumnTransformer(transformers=[('ohe', OneHotEncoder(handle_unknown='ignore'), cat_cols)], remainder='passthrough')\n",
        "X_train = ct.fit_transform(X_train)\n",
        "X_test = ct.transform(X_test)\n",
        "\n",
        "# Dividir el conjunto de entrenamiento en entrenamiento y validación\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, train_size=0.8, test_size=0.2, random_state=0, stratify=y_train)\n",
        "\n",
        "# Crear una instancia del modelo de Regresión Logística\n",
        "lr = LogisticRegression(random_state=0)\n",
        "\n",
        "# Entrenar el modelo con el conjunto de entrenamiento\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# Predecir los valores en el conjunto de validación\n",
        "y_valid_pred = lr.predict(X_valid)\n",
        "\n",
        "# Calcular la precisión (accuracy) del modelo en el conjunto de validación\n",
        "acc = accuracy_score(y_valid, y_valid_pred)\n",
        "print(\"Precisión en el conjunto de validación:\", acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4u700JNhMrj1"
      },
      "source": [
        "El mensaje de advertencia indica que el algoritmo de optimización no convergió antes de alcanzar el número máximo de iteraciones. Esto puede deberse a que el modelo necesita más iteraciones para converger o porque el conjunto de datos no está bien escalado. Una opción es aumentar el número máximo de iteraciones a través del parámetro max_iter del modelo de Regresión Logística.\n",
        "\n",
        "Para evaluar la calidad del modelo, se utilizó la precisión (accuracy), que es la proporción de predicciones correctas sobre el total de predicciones."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}